---
title: "Practical Machine Learning Week 4 Project"
author:"Adesh Thakur
date: "14 dec 2019"
output: html_document
---



## Start of Data Analysis


```{r loadData, message=FALSE, warning=FALSE}
library(readr)
library(dplyr)
pml_training <- read_csv("D:/Coursera Data Science/Practical Machine Learning/week 4 project/pml-training.csv")
pml_testing <- read_csv("D:/Coursera Data Science/Practical Machine Learning/week 4 project/pml-testing.csv")
# Cleaning Data
NAcolumns <- colnames(pml_training[,which(colMeans(is.na(pml_training)) > 0.5)]) # Find columns with more than 50% NAs in them.
pml_training <- pml_training %>% select(-one_of(NAcolumns)) %>% filter(complete.cases(.)) # remove columns and rows with NA
pml_training <- select(pml_training,-(1:7)) # remove first 7 columns as they do not contain information needed for our analysis
# Do the same for testing data
pml_testing <- pml_testing %>% select(-one_of(NAcolumns)) %>% filter(complete.cases(.))
pml_testing <- select(pml_testing,-(1:7))
```
### 2. Learning on Training Data
```{r trainData, message=FALSE, warning=FALSE}
library(caret)
set.seed(1688)
# Subset training data set so that we can train and test our predictors
inTrain <- createDataPartition(pml_training$classe, p=0.7, list = FALSE)
training <- pml_training[inTrain,]
testing <- pml_training[-inTrain,]
# Create a data frame to store overall accuracies for comparison
Accuracy <- data.frame(matrix(ncol = 3, nrow = 1))
colnames(Accuracy) <- c("DecisionTree", "RandomForest", "GBM")
# We will use 3 classification methods and compare their accuracy: Decision Tree, Random Forest and Generalized Boosted Regression Model (GBM)
# Start Decision Tree
library(rpart)
library(rpart.plot)
library(e1071)
modFitTree <- rpart(classe ~., data = training, method = "class")
predTree <- predict(modFitTree, newdata = testing, type = "class")
confTree <- confusionMatrix(predTree, as.factor(testing$classe))
Accuracy$DecisionTree <- as.numeric(confTree$overall['Accuracy'])
```
### Decision Tree Plot
```{r plotDecisionTree, message=FALSE, warning=FALSE}
rpart.plot(modFitTree,tweak = 1.2, cex=0.3)
```
  
#### Accuracy of Decision Tree
```{r confTree}
confTree
```
  
### Random Forest Analysis
```{r randomForest,message=FALSE, warning=FALSE}
modFitRF <- train(classe ~., data = training, method = "rf")
predRF <- predict(modFitRF, newdata = testing)
confRF <- confusionMatrix(predRF, as.factor(testing$classe))
Accuracy$RandomForest <- as.numeric(confRF$overall['Accuracy'])
```
#### Accuracy of Random Forest
```{r}
confRF
```
  
# Analysis
```{r GMB,message=FALSE, warning=FALSE}
modFitGBM  <- train(classe ~ ., data=training, method = "gbm",verbose = FALSE)
predGBM <- predict(modFitGBM, newdata = testing)
confGBM <- confusionMatrix(predGBM, as.factor(testing$classe))
Accuracy$GBM <- as.numeric(confGBM$overall['Accuracy'])
```
  
#### Accuracy
```{r}
confGBM
```

import tensorflow as tf
import tensorlayer as tl
import numpy as np
from tensorlayer.cost import cross_entropy_seq, cross_entropy_seq_with_mask
from tqdm import tqdm
from sklearn.utils import shuffle
from data.twitter import data
from tensorlayer.models.seq2seq import Seq2seq
from tensorlayer.models.seq2seq_with_attention import Seq2seqLuongAttention
import os


def initial_setup(data_corpus):
    metadata, idx_q, idx_a = data.load_data(PATH='data/{}/'.format(data_corpus))
    (trainX, trainY), (testX, testY), (validX, validY) = data.split_dataset(idx_q, idx_a)
    trainX = tl.prepro.remove_pad_sequences(trainX.tolist())
    trainY = tl.prepro.remove_pad_sequences(trainY.tolist())
    testX = tl.prepro.remove_pad_sequences(testX.tolist())
    testY = tl.prepro.remove_pad_sequences(testY.tolist())
    validX = tl.prepro.remove_pad_sequences(validX.tolist())
    validY = tl.prepro.remove_pad_sequences(validY.tolist())
    return metadata, trainX, trainY, testX, testY, validX, validY



if __name__ == "__main__":
    data_corpus = "twitter"

    #data preprocessing
    metadata, trainX, trainY, testX, testY, validX, validY = initial_setup(data_corpus)

    # Parameters
    src_len = len(trainX)
    tgt_len = len(trainY)

    assert src_len == tgt_len

    batch_size = 32
    n_step = src_len // batch_size
    src_vocab_size = len(metadata['idx2w']) # 8002 (0~8001)
    emb_dim = 1024

    word2idx = metadata['w2idx']   # dict  word 2 index
    idx2word = metadata['idx2w']   # list index 2 word

    unk_id = word2idx['unk']   # 1
    pad_id = word2idx['_']     # 0

    start_id = src_vocab_size  # 8002
    end_id = src_vocab_size + 1  # 8003

    word2idx.update({'start_id': start_id})
    word2idx.update({'end_id': end_id})
    idx2word = idx2word + ['start_id', 'end_id']

    src_vocab_size = tgt_vocab_size = src_vocab_size + 2

    num_epochs = 50
    vocabulary_size = src_vocab_size
    


    def inference(seed, top_n):
        model_.eval()
        seed_id = [word2idx.get(w, unk_id) for w in seed.split(" ")]
        sentence_id = model_(inputs=[[seed_id]], seq_length=20, start_token=start_id, top_n = top_n)
        sentence = []
        for w_id in sentence_id[0]:
            w = idx2word[w_id]
            if w == 'end_id':
                break
            sentence = sentence + [w]
        return sentence

    decoder_seq_length = 20
    model_ = Seq2seq(
        decoder_seq_length = decoder_seq_length,
        cell_enc=tf.keras.layers.GRUCell,
        cell_dec=tf.keras.layers.GRUCell,
        n_layer=3,
        n_units=256,
        embedding_layer=tl.layers.Embedding(vocabulary_size=vocabulary_size, embedding_size=emb_dim),
        )
    

    # Uncomment below statements if you have already saved the model

    # load_weights = tl.files.load_npz(name='model.npz')
    # tl.files.assign_weights(load_weights, model_)

    optimizer = tf.optimizers.Adam(learning_rate=0.001)
    model_.train()

    seeds = ["happy birthday have a nice day",
                 "donald trump won last nights presidential debate according to snap online polls"]
    for epoch in range(num_epochs):
        model_.train()
        trainX, trainY = shuffle(trainX, trainY, random_state=0)
        total_loss, n_iter = 0, 0
        for X, Y in tqdm(tl.iterate.minibatches(inputs=trainX, targets=trainY, batch_size=batch_size, shuffle=False), 
                        total=n_step, desc='Epoch[{}/{}]'.format(epoch + 1, num_epochs), leave=False):

            X = tl.prepro.pad_sequences(X)
            _target_seqs = tl.prepro.sequences_add_end_id(Y, end_id=end_id)
            _target_seqs = tl.prepro.pad_sequences(_target_seqs, maxlen=decoder_seq_length)
            _decode_seqs = tl.prepro.sequences_add_start_id(Y, start_id=start_id, remove_last=False)
            _decode_seqs = tl.prepro.pad_sequences(_decode_seqs, maxlen=decoder_seq_length)
            _target_mask = tl.prepro.sequences_get_mask(_target_seqs)


### Prediction on Test Data Set
Here are the results of our prediction with the data from the testing set:
```{r Predict, message=FALSE, warning=FALSE}
predFinal <- predict(modFitRF, newdata=pml_testing)
predFinal
```
 
